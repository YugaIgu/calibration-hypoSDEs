{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import time\n",
    "import scipy.stats\n",
    "from jax.scipy.stats import norm\n",
    "import scipy.optimize\n",
    "import symnum.numpy as snp\n",
    "import jax.numpy as jnp\n",
    "from jax.scipy.linalg import cho_solve\n",
    "from jax import jit, grad, value_and_grad\n",
    "from jax.lax import scan\n",
    "import matplotlib.pyplot as plt\n",
    "from jax.config import config\n",
    "config.update('jax_enable_x64', True)\n",
    "config.update('jax_platform_name', 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gle_protein_folding:\n",
    "    def __init__(self, param, initial_value, step_size_data, step_size_sim, num_data, num_simulation, mass, temp):\n",
    "        self.param = param \n",
    "        self.initial_value = initial_value  \n",
    "        self.step_size_data = step_size_data\n",
    "        self.step_size_sim = step_size_sim\n",
    "        self.num_data = num_data\n",
    "        self.num_simulation = num_simulation\n",
    "        self.mass = mass\n",
    "        self.temp = temp\n",
    "    \n",
    "    def grad_potential(self, q, a = 1200, b=0.30, c=0.90, d = 0.001):\n",
    "        return 2*a*((q-b)*((q-c)**2) + (q-c)*((q-b)**2)) + 3*d*(q**2)\n",
    "    \n",
    "    def hess_potential(self, q, a =1200, b=0.30, c=0.90, d= 0.001):\n",
    "        return 2*a*((q-c)**2 + 4*(q-c)*(q-b) + (q-b)**2) + 6*d*q\n",
    "\n",
    "    def calc_A_q(self, q, θ):\n",
    "        dt = self.step_size_data\n",
    "        c_1, c_2, τ_1, τ_2 = θ\n",
    "        hess_U = self.hess_potential(q)\n",
    "        sum_ratio = c_1/τ_1 + c_2/τ_2\n",
    "        return jnp.array(\n",
    "            [\n",
    "                dt - (hess_U + sum_ratio)* (dt**3)/6,\n",
    "                (dt**2)/2 - (dt**3)/(6*τ_1), \n",
    "                (dt**2)/2 - (dt**3)/(6*τ_2)\n",
    "             ]\n",
    "        )\n",
    "\n",
    "    def calc_A_h(self, q, θ):  \n",
    "        dt = self.step_size_data\n",
    "        c_1, c_2, τ_1, τ_2 = θ\n",
    "        hess_U = self.hess_potential(q)\n",
    "        sum_ratio = c_1/τ_1 + c_2/τ_2\n",
    "        return jnp.array(\n",
    "            [ \n",
    "            [1 - (hess_U + sum_ratio) * (dt**2)/2, dt - (dt**2)/(2*τ_1), dt - (dt**2)/(2*τ_2)], \n",
    "            [-(c_1/τ_1)*dt, 1 - dt/τ_1, 0.0, 0.0],\n",
    "            [-(c_2/τ_2)*dt, 0.0, 1 - dt/τ_2, 0.0],\n",
    "            ])\n",
    "    \n",
    "    def calc_mu_q(self, q, θ):\n",
    "        dt = self.step_size_data\n",
    "        mass = self.mass \n",
    "        grad_U = self.grad_potential(q)\n",
    "        return q - grad_U*(dt**2)/2\n",
    "\n",
    "    def matrix_A(self, q, θ): \n",
    "        c_1, c_2, τ_1, τ_2  = θ\n",
    "        dt = self.step_size_data\n",
    "        hess_U = self.hess_potential(q)\n",
    "        mass = self.mass\n",
    "        sum_ratio = c_1/τ_1 + c_2/τ_2\n",
    "        return jnp.array([\n",
    "            [dt - (hess_U + sum_ratio)*(dt**3)/6, \n",
    "            (dt**2)/2 - (dt**3)/(6*τ_1), \n",
    "            (dt**2)/2 - (dt**3)/(6*τ_2)\n",
    "            ],\n",
    "            [1 - (hess_U + sum_ratio) * (dt**2)/2, \n",
    "            dt - (dt**2)/(2*τ_1), \n",
    "            dt - (dt**2)/(2*τ_2)\n",
    "            ], \n",
    "            [-(c_1/τ_1)*dt, 1 - dt/τ_1, 0.0],\n",
    "            [-(c_2/τ_2)*dt, 0.0, 1 - dt/τ_2]\n",
    "            ]) \n",
    "    \n",
    "    # This is used to generate the true trajectories of sample paths\n",
    "    def mean_one_step_sim(self, x, θ): \n",
    "        q = x[0]\n",
    "        h = x[1:] \n",
    "        dt = self.step_size_sim\n",
    "        c_1, c_2, τ_1, τ_2 = θ\n",
    "        grad_U = self.grad_potential(q)\n",
    "        hess_U = self.hess_potential(q)\n",
    "        sum_ratio = c_1/τ_1 + c_2/τ_2\n",
    "        mass = self.mass\n",
    "        matrix_A = jnp.array([\n",
    "            [dt - (hess_U + sum_ratio)*(dt**3)/6, \n",
    "            (dt**2)/2 - (dt**3)/(6*τ_1), \n",
    "            (dt**2)/2 - (dt**3)/(6*τ_2)\n",
    "            ],\n",
    "            [1 - (hess_U + sum_ratio) * (dt**2)/2, \n",
    "            dt - (dt**2)/(2*τ_1), \n",
    "            dt - (dt**2)/(2*τ_2)\n",
    "            ], \n",
    "            [-(c_1/τ_1)*dt, 1 - dt/τ_1, 0.0],\n",
    "            [-(c_2/τ_2)*dt, 0.0, 1 - dt/τ_2]\n",
    "            ]) \n",
    "        return jnp.array([q  - grad_U*(dt**2)/2, - grad_U*dt, 0.0, 0.0]) + jnp.dot(matrix_A, h) \n",
    "\n",
    "    \n",
    "    def mean_one_step(self, current_q, current_h, θ):\n",
    "        dt = self.step_size_data\n",
    "        c_1, c_2, τ_1, τ_2 = θ\n",
    "        grad_U = self.grad_potential(current_q)\n",
    "        hess_U = self.hess_potential(current_q)\n",
    "        sum_ratio = c_1/τ_1 + c_2/τ_2 \n",
    "        mass = self.mass\n",
    "        matrix_A = jnp.array(\n",
    "            [\n",
    "            [dt - (hess_U + sum_ratio)* (dt**3)/6, (dt**2)/2 - (dt**3)/(6*τ_1), (dt**2)/2 - (dt**3)/(6*τ_2)],\n",
    "            [1 - (hess_U + sum_ratio) * (dt**2)/2, dt - (dt**2)/(2*τ_1), dt - (dt**2)/(2*τ_2)], \n",
    "            [-(c_1/τ_1)*dt, 1 - dt/τ_1, 0.0],\n",
    "            [-(c_2/τ_2)*dt, 0.0, 1 - dt/τ_2]\n",
    "            ])\n",
    "\n",
    "        return jnp.array([current_q - grad_U*(dt**2)/(2*mass),  - grad_U*dt, 0.0, 0.0]) + jnp.dot(matrix_A, current_h) \n",
    "    \n",
    "    def covariance_one_step_sim(self, θ):\n",
    "        dt = self.step_size_sim\n",
    "        c_1, c_2, τ_1, τ_2 = θ\n",
    "        Σ_33 = 2*self.temp*c_1/(τ_1**2)\n",
    "        Σ_44 = 2*self.temp*c_2/(τ_2**2)\n",
    "        sum_Σ = Σ_33 + Σ_44\n",
    "        return jnp.array([\n",
    "            [sum_Σ*(dt**5)/20, sum_Σ*(dt**4)/8, Σ_33*(dt**3)/6, Σ_44*(dt**3)/6], \n",
    "            [sum_Σ*(dt**4)/8, sum_Σ*(dt**3)/3, Σ_33*(dt**2)/2, Σ_44*(dt**2)/2], \n",
    "            [Σ_33*(dt**3)/6, Σ_33*(dt**2)/2, Σ_33*dt, 0.0],\n",
    "            [Σ_44*(dt**3)/6, Σ_44*(dt**2)/2, 0.0, Σ_44*dt]\n",
    "            ])\n",
    "    \n",
    "    def covariance_one_step(self, θ):\n",
    "        dt = self.step_size_data\n",
    "        c_1, c_2, τ_1, τ_2 = θ\n",
    "        Σ_33 = 2*self.temp*c_1/(τ_1**2)\n",
    "        Σ_44 = 2*self.temp*c_2/(τ_2**2)\n",
    "        sum_Σ = Σ_33 + Σ_44\n",
    "        return jnp.array([\n",
    "            [sum_Σ*(dt**5)/20, sum_Σ*(dt**4)/8, Σ_33*(dt**3)/6, Σ_44*(dt**3)/6], \n",
    "            [sum_Σ*(dt**4)/8, sum_Σ*(dt**3)/3, Σ_33*(dt**2)/2, Σ_44*(dt**2)/2], \n",
    "            [Σ_33*(dt**3)/6, Σ_33*(dt**2)/2, Σ_33*dt, 0.0],\n",
    "            [Σ_44*(dt**3)/6, Σ_44*(dt**2)/2, 0.0, Σ_44*dt]\n",
    "            ])\n",
    "\n",
    "    def generate_sample_paths(self, θ, seed=20230704):\n",
    "        np.random.seed(seed)\n",
    "        seq_rvs = np.random.multivariate_normal(np.zeros(4), self.covariance_one_step_sim(θ), size=self.num_simulation)\n",
    "        x_0 = self.initial_value \n",
    "        \n",
    "        @jit\n",
    "        def step_func(x, noise):\n",
    "            x_next = self.mean_one_step_sim(x, θ) + noise\n",
    "            return x_next, x_next \n",
    "        \n",
    "        _, x_seq = scan(step_func, x_0, seq_rvs) \n",
    "\n",
    "        return jnp.concatenate((x_0[None], x_seq))\n",
    "    \n",
    "    def prediction_covariance(self, q, forward_filter_covariance, θ):\n",
    "        Σ =self.covariance_one_step(θ)\n",
    "        A = self.matrix_A(q, θ)\n",
    "        pred_cov =  Σ + A @ forward_filter_covariance @ A.T \n",
    "        return pred_cov[0,0], pred_cov[1:,0], pred_cov[1:, 1:]\n",
    "    \n",
    "    \n",
    "    def prediction_mean(self, q, forward_filter_mean, θ):\n",
    "        pred_mean = self.mean_one_step(q, forward_filter_mean, θ) \n",
    "        pred_mean_q = pred_mean[0]\n",
    "        pred_mean_h = pred_mean[1:]\n",
    "        return pred_mean_q, pred_mean_h\n",
    "    \n",
    "\n",
    "    def forward_filter_mean_cov_one_step(self, current_q, next_q, forward_filter_mean, forward_filter_covariance, θ):\n",
    "        μ_q, μ_h = self.prediction_mean(current_q, forward_filter_mean, θ)\n",
    "        Λ_qq, Λ_hq, Λ_hh = self.prediction_covariance(current_q, forward_filter_covariance, θ) \n",
    "        next_filter_mean = μ_h + ((next_q - μ_q)/Λ_qq)*Λ_hq\n",
    "        mat = jnp.outer(Λ_hq, Λ_hq)\n",
    "        next_filter_cov = Λ_hh - mat / Λ_qq\n",
    "        return next_filter_mean, next_filter_cov\n",
    "    \n",
    "    \n",
    "    def forward_filter_mean_cov_paths_scan(self, q_paths, initial_mean, initial_cov, θ):\n",
    "        @jit\n",
    "        def step_func(filter_mean_cov, q_paths_current_next):\n",
    "            filter_mean, filter_cov = filter_mean_cov\n",
    "            q_current, q_next = q_paths_current_next\n",
    "            filter_next = self.forward_filter_mean_cov_one_step(q_current, q_next, filter_mean, filter_cov, θ)\n",
    "            return filter_next, filter_next \n",
    "        \n",
    "        _, filter_mean_cov = scan(step_func, (initial_mean, initial_cov), (q_paths[:-1], q_paths[1:]))\n",
    "        filter_mean, filter_cov = filter_mean_cov\n",
    "\n",
    "        return jnp.concatenate((initial_mean[None], filter_mean)), jnp.concatenate((initial_cov[None], filter_cov)) \n",
    "    \n",
    "    def get_contrast_function_scan(self, θ, q_paths, initial_mean, initial_cov):\n",
    "        filter_mean_paths, filter_cov_paths = self.forward_filter_mean_cov_paths_scan(q_paths, initial_mean, initial_cov, θ)\n",
    "        initial_log_likelihood = norm.logpdf(q_paths[0], loc = q_paths[0], scale = 1.0)\n",
    "        Σ = self.covariance_one_step(θ)\n",
    "\n",
    "        @jit\n",
    "        def step_func(loglikelihood, qset_and_filtermeancov):\n",
    "            q_current, q_next, filter_mean, filter_cov = qset_and_filtermeancov\n",
    "            A_q = self.calc_A_q(q_current, θ)\n",
    "            q_mean = self.calc_mu_q(q_current, θ) + jnp.dot(A_q, filter_mean)\n",
    "            vec = A_q @ filter_cov\n",
    "            scalar = jnp.dot(vec, A_q)\n",
    "            q_scale = jnp.sqrt(scalar + Σ[0,0])\n",
    "            loglikelihood_next = loglikelihood + norm.logpdf(q_next, q_mean, q_scale)\n",
    "            return loglikelihood_next, loglikelihood_next\n",
    "        \n",
    "        _, log_likelihood_seq = scan(step_func, initial_log_likelihood, (q_paths[:-1], q_paths[1:], filter_mean_paths[:-1,:], filter_cov_paths[:-1,:,:]))\n",
    "\n",
    "        return -2*log_likelihood_seq[-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample path of observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_simulation = 1e-4 # step size for synthetic data \n",
    "dt_obs = 1e-3  # step size for the observation \n",
    "T = 1500 # Time length of data step\n",
    "n_simulation = int(T / dt_simulation)\n",
    "sub_interval = int(dt_obs/dt_simulation)\n",
    "n_data = int(T / dt_obs) # number of data \n",
    "θ_true = [2.214*1e-1, 1.2, 0.007, 4.6] # param θ = (c_1, c_2, c_3, τ_1, τ_2, τ_3) \n",
    "x_0 = jnp.array([0.0, 0.0, 0.0, 0.0]) # initial value  \n",
    "t_seq_sim = np.arange(int(T / dt_simulation) + 1) * dt_simulation\n",
    "model = gle_protein_folding(θ_true, x_0, dt_obs, dt_simulation, n_data, n_simulation, mass=1.0, temp=2.949)\n",
    "initial_mean = jnp.array([0.0, 0.0, 0.0])\n",
    "initial_cov = jnp.array([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]])\n",
    "\n",
    "seed = 20230707\n",
    "model = gle_protein_folding(θ_true, x_0, dt_obs, dt_simulation, n_data, n_simulation, mass=1.0, temp=2.949)\n",
    "x_seq_obs = model.generate_sample_paths(θ_true, seed)\n",
    "q_paths_sim = x_seq_obs[:, 0]\n",
    "t_seq_obs = t_seq_sim[::sub_interval]\n",
    "q_paths_obs = q_paths_sim[::sub_interval]\n",
    "fig, axs = plt.subplots(figsize=(6.0, 5.0))\n",
    "axs.plot(t_seq_obs, q_paths_obs, linewidth=1.0)\n",
    "axs.set_ylabel(r\"$q_t$\", fontsize=16)\n",
    "axs.set_xlabel(r'$\\mathrm{time} \\, (t)$', fontsize=16)\n",
    "plt.show()\n",
    "x_0 = x_seq_obs[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computation of maximum likelihood estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting for observations\n",
    "num_sampling = 50\n",
    "seed = 20230707\n",
    "dt_simulation = 1e-4 # step size for synthetic data \n",
    "dt_obs = 1e-3  # step size for the observation \n",
    "T = 1500 # Time length of data step\n",
    "n_simulation = int(T / dt_simulation)\n",
    "sub_interval = int(dt_obs/dt_simulation)\n",
    "n_data = int(T / dt_obs) # number of data \n",
    "t_seq_sim = np.arange(int(T / dt_simulation) + 1) * dt_simulation\n",
    "x_0 = x_seq_obs[-1]\n",
    "θ_true = [2.214*1e-1, 1.2, 0.007, 4.6] # param θ = (c_1, c_2, τ_1, τ_2) \n",
    "model = gle_protein_folding(θ_true, x_0, dt_obs, dt_simulation, n_data, n_simulation, mass=1.0, temp=2.949)\n",
    "x_seq_obs = model.generate_sample_paths(θ_true, seed)\n",
    "q_paths_sim = x_seq_obs[:, 0]\n",
    "t_seq_obs = t_seq_sim[::sub_interval]\n",
    "q_paths_obs = q_paths_sim[::sub_interval]\n",
    "x_seq_0 = x_seq_obs[0]\n",
    "initial_mean = jnp.array([0.0, 0.0, 0.0])\n",
    "initial_cov = jnp.array([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "θ_output = np.zeros(len(θ_true)*num_sampling).reshape(num_sampling,len(θ_true))\n",
    "θ_0 = jnp.array([1e-1, 1.0, 1e-2, 10.0])\n",
    "\n",
    "for k in range(num_sampling):\n",
    "    print(\"Compute the observations -- Start\")\n",
    "    x_seq_sim = model.generate_sample_paths(θ_true, seed)\n",
    "    print(\"Compute the observations -- End\")\n",
    "    q_paths_sim = x_seq_sim[:, 0]\n",
    "    q_paths_obs = q_paths_sim[::sub_interval]\n",
    "    inv_data = int(500/dt_obs)\n",
    "    q_paths_obs = q_paths_obs[inv_data:]\n",
    "    arg = (q_paths_obs, initial_mean, initial_cov)\n",
    "    count = 0\n",
    "    def cbf(X):\n",
    "        global count\n",
    "        count += 1\n",
    "        f = model.get_contrast_function_scan(X, q_paths_obs, initial_mean, initial_cov)\n",
    "        print('%d\\t%f\\t%f\\t%f\\t%f\\t%f' % (count, X[0], X[1], X[2], X[3], f))\n",
    "        \n",
    "    print(\"Optimisation--Start\")\n",
    "    res = scipy.optimize.minimize(\n",
    "        model.get_contrast_function_scan, θ_0, args=arg, \n",
    "        method='Nelder-Mead', \n",
    "        callback=cbf, \n",
    "        options={\"maxiter\":1000})\n",
    "    print(\"Optimisation--End\")\n",
    "    print(res)\n",
    "    print(k)\n",
    "    θ_output[k] = res.x\n",
    "    seed += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(f'MLE_GLE_protein_folding_partial={T}_dt_obs_{dt_obs}_dt_sim_{dt_simulation}.csv', 'w')\n",
    "writer = csv.writer(f, delimiter='\\t')\n",
    "for i in range (num_sampling):\n",
    "    writer.writerow(θ_output[i])\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
