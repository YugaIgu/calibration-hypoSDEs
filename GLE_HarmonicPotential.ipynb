{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import time\n",
    "import scipy.stats\n",
    "from jax.scipy.stats import norm\n",
    "import scipy.optimize\n",
    "import symnum\n",
    "import symnum.numpy as snp\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "from jax.scipy.linalg import cho_solve\n",
    "from jax import jit, vmap, grad, value_and_grad\n",
    "from jax.lax import scan\n",
    "from jax.example_libraries.optimizers import adam\n",
    "import matplotlib.pyplot as plt\n",
    "from jax.config import config\n",
    "config.update('jax_enable_x64', True)\n",
    "config.update('jax_platform_name', 'cpu')\n",
    "import simsde "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hypo_gle_ho:\n",
    "    def __init__(self, param, initial_value, step_size_data, step_size_sim, num_data, num_simulation):\n",
    "        self.param = param # θ = (D, λ, α, σ)   \n",
    "        self.initial_value = initial_value  \n",
    "        self.step_size_data = step_size_data\n",
    "        self.step_size_sim = step_size_sim\n",
    "        self.num_data = num_data\n",
    "        self.num_simulation = num_simulation\n",
    "\n",
    "    def calc_A_q(self, θ): # θ = (D, λ, α, σ)    \n",
    "        dt = self.step_size_data\n",
    "        D, λ, α ,σ = θ\n",
    "        return jnp.array(\n",
    "            [dt - (D + (λ**2)) * (dt**3) /6, λ * (dt**2) /2 - λ * α * (dt**3) / 6]\n",
    "            )\n",
    "\n",
    "    def calc_A_h(self, θ): \n",
    "        dt = self.step_size_data\n",
    "        D, λ, α ,σ = θ\n",
    "        return jnp.array(\n",
    "            [ \n",
    "            [1 - (D + (λ**2)) * (dt**2)/2, λ * dt - λ*α*(dt**2)/2], \n",
    "            [-λ*dt, 1 - α*dt]\n",
    "            ])\n",
    "    \n",
    "    def calc_mu_q(self, q, θ):\n",
    "        D = θ[0]\n",
    "        dt = self.step_size_data\n",
    "        return q - D*q*(dt**2)/2 \n",
    "\n",
    "    def matrix_A(self, θ):\n",
    "        dt = self.step_size_data\n",
    "        D, λ, α ,σ = θ\n",
    "        return jnp.array([\n",
    "            [dt - (D + (λ**2)) * (dt**3) /6, λ * (dt**2) /2 - λ * α * (dt**3) / 6],\n",
    "            [1 - (D + (λ**2)) * (dt**2) /2, λ * dt - λ * α * (dt**2) /2], \n",
    "            [-λ*dt, 1 - α*dt]\n",
    "            ]) \n",
    "    \n",
    "    # This is used to generate the true trajectories of sample paths \n",
    "    # x = (q, h) \n",
    "    def mean_one_step_sim(self, x, θ): \n",
    "        dt = self.step_size_sim\n",
    "        D, λ, α ,σ = θ\n",
    "        q = x[0]\n",
    "        h = x[1:]\n",
    "        matrix_A = jnp.array([\n",
    "            [dt - (D + (λ**2)) * (dt**3) /6, λ * (dt**2) /2 - λ * α * (dt**3) / 6],\n",
    "            [1 - (D + (λ**2)) * (dt**2) /2, λ * dt - λ * α * (dt**2) /2], \n",
    "            [-λ*dt, 1 - α*dt]\n",
    "            ]) \n",
    "        return jnp.array([q - D*q*(dt**2)/2, - D*q*dt, 0]) + jnp.dot(matrix_A, h) \n",
    "    \n",
    "    def mean_one_step(self, current_q, current_h, θ):\n",
    "        dt = self.step_size_data\n",
    "        D, λ, α ,σ = θ\n",
    "        matrix_A = jnp.array([\n",
    "            [dt - (D + (λ**2)) * (dt**3) /6, λ * (dt**2) /2 - λ * α * (dt**3) / 6],\n",
    "            [1 - (D + (λ**2)) * (dt**2) /2, λ * dt - λ * α * (dt**2) /2], \n",
    "            [-λ*dt, 1 - α*dt]\n",
    "            ]) \n",
    "        return jnp.array([current_q - D*current_q*(dt**2)/2,  - D*current_q*dt, 0]) + jnp.dot(matrix_A, current_h) \n",
    "    \n",
    "    def covariance_one_step_sim(self, θ):\n",
    "        dt = self.step_size_sim\n",
    "        D, λ, α ,σ = θ\n",
    "        return (σ**2)*jnp.array([\n",
    "            [(λ**2)*(dt**5)/20, (λ**2)*(dt**4)/8, λ*(dt**3)/6], \n",
    "            [(λ**2)*(dt**4)/8, (λ**2)*(dt**3)/3, λ*(dt**2)/2], \n",
    "            [λ*(dt**3)/6, λ*(dt**2)/2, dt]\n",
    "            ])\n",
    "    \n",
    "    def covariance_one_step(self, θ):\n",
    "        dt = self.step_size_data\n",
    "        D, λ, α ,σ = θ\n",
    "        return (σ**2)*jnp.array([\n",
    "            [(λ**2)*(dt**5)/20, (λ**2)*(dt**4)/8, λ*(dt**3)/6], \n",
    "            [(λ**2)*(dt**4)/8, (λ**2)*(dt**3)/3, λ*(dt**2)/2], \n",
    "            [λ*(dt**3)/6, λ*(dt**2)/2, dt]\n",
    "            ])\n",
    "\n",
    "    def generate_sample_paths(self, θ, seed=20230606):\n",
    "        np.random.seed(seed)\n",
    "        seq_rvs = np.random.multivariate_normal(np.zeros(3), self.covariance_one_step_sim(θ), size=self.num_simulation)\n",
    "        x_0 = self.initial_value\n",
    "        \n",
    "        @jit\n",
    "        def step_func(x, noise):\n",
    "            x_next = self.mean_one_step_sim(x, θ) + noise\n",
    "            return x_next, x_next \n",
    "        \n",
    "        _, x_seq = scan(step_func, x_0, seq_rvs) \n",
    "\n",
    "        return jnp.concatenate((x_0[None], x_seq))\n",
    "    \n",
    "    def prediction_covariance(self, forward_filter_covariance, θ):\n",
    "        Σ =self.covariance_one_step(θ)\n",
    "        A = self.matrix_A(θ)\n",
    "        pred_cov =  Σ + A @ forward_filter_covariance @ A.T \n",
    "        pred_cov_qq = pred_cov[0,0]\n",
    "        pred_cov_hq = pred_cov[1:,0]\n",
    "        pred_cov_hh = pred_cov[1:, 1:]\n",
    "        return pred_cov_qq, pred_cov_hq, pred_cov_hh\n",
    "    \n",
    "    \n",
    "    def prediction_mean(self, q, forward_filter_mean, θ):\n",
    "        pred_mean = self.mean_one_step(q, forward_filter_mean, θ) \n",
    "        pred_mean_q = pred_mean[0]\n",
    "        pred_mean_h = pred_mean[1:]\n",
    "        return pred_mean_q, pred_mean_h\n",
    "    \n",
    "\n",
    "    def forward_filter_mean_cov_one_step(self, current_q, next_q, forward_filter_mean, forward_filter_covariance, θ):\n",
    "        μ_q, μ_h = self.prediction_mean(current_q, forward_filter_mean, θ)\n",
    "        Λ_qq, Λ_hq, Λ_hh = self.prediction_covariance(forward_filter_covariance, θ) \n",
    "        next_filter_mean = μ_h + ((next_q - μ_q)/Λ_qq)*Λ_hq\n",
    "        mat = jnp.array([[Λ_hq[0]**2, Λ_hq[0]*Λ_hq[1]], [Λ_hq[0]*Λ_hq[1], Λ_hq[1]**2]])\n",
    "        next_filter_cov = Λ_hh - mat / Λ_qq\n",
    "        return next_filter_mean, next_filter_cov\n",
    "    \n",
    "    \n",
    "    def forward_filter_mean_cov_paths_scan(self, q_paths, initial_mean, initial_cov, θ):\n",
    "        @jit\n",
    "        def step_func(filter_mean_cov, q_paths_current_next):\n",
    "            filter_mean, filter_cov = filter_mean_cov\n",
    "            q_current, q_next = q_paths_current_next\n",
    "            filter_next = self.forward_filter_mean_cov_one_step(q_current, q_next, filter_mean, filter_cov, θ)\n",
    "            return filter_next, filter_next \n",
    "        \n",
    "        _, filter_mean_cov = scan(step_func, (initial_mean, initial_cov), (q_paths[:-1], q_paths[1:]))\n",
    "        filter_mean, filter_cov = filter_mean_cov\n",
    "\n",
    "        return jnp.concatenate((initial_mean[None], filter_mean)), jnp.concatenate((initial_cov[None], filter_cov)) \n",
    "    \n",
    "    def get_contrast_function_scan(self, θ, q_paths, initial_mean, initial_cov):\n",
    "        filter_mean_paths, filter_cov_paths = self.forward_filter_mean_cov_paths_scan(q_paths, initial_mean, initial_cov, θ)\n",
    "        initial_log_likelihood = norm.logpdf(q_paths[0], loc = q_paths[0], scale = 1.0)\n",
    "        A_q = self.calc_A_q(θ)\n",
    "        Σ = self.covariance_one_step(θ)\n",
    "\n",
    "        @jit\n",
    "        def step_func(loglikelihood, qset_and_filtermeancov):\n",
    "            q_current, q_next, filter_mean, filter_cov = qset_and_filtermeancov\n",
    "            q_mean = self.calc_mu_q(q_current, θ) + jnp.dot(A_q, filter_mean)\n",
    "            vec = A_q @ filter_cov\n",
    "            scalar = jnp.dot(vec, A_q)\n",
    "            q_scale = jnp.sqrt(scalar + Σ[0,0])\n",
    "            loglikelihood_next = loglikelihood + norm.logpdf(q_next, q_mean, q_scale)\n",
    "            return loglikelihood_next, loglikelihood_next\n",
    "        \n",
    "        _, log_likelihood_seq = scan(step_func, initial_log_likelihood, (q_paths[:-1], q_paths[1:], filter_mean_paths[:-1,:], filter_cov_paths[:-1,:,:]))\n",
    "\n",
    "        return -2*log_likelihood_seq[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x[0]: extended space (rough), x[1]: momentum, x[2]:position\n",
    "\n",
    "def drift_position(x, θ):\n",
    "    return snp.array([x[1]])\n",
    "\n",
    "def drift_momentum(x, θ):\n",
    "    D, λ, *_ = θ\n",
    "    # the potential function q -> V(q) is assumed to be V(q) = q^2 /2 \n",
    "    return snp.array([- D*x[2] + λ*x[0]])\n",
    "\n",
    "def diff_coeff_rough(x, θ):\n",
    "    *_, σ = θ\n",
    "    return snp.array([[σ]])\n",
    "\n",
    "def drift_rough(x, θ):\n",
    "    D, λ, α, *_ = θ\n",
    "    return snp.array([- λ*x[1] - α*x[0]])\n",
    "\n",
    "def drift_smooth(x, θ):\n",
    "    return snp.concatenate((drift_momentum(x, θ), drift_position(x, θ)))\n",
    "\n",
    "def drift_func(x, θ):\n",
    "    return snp.concatenate((drift_rough(x, θ), drift_smooth(x, θ)))\n",
    "\n",
    "def diff_coeff(x, θ):\n",
    "    *_, σ = θ\n",
    "    return snp.array([[σ], [0], [0]])\n",
    "\n",
    "dim_x = 3\n",
    "dim_s1 = 1\n",
    "dim_s2 = 1\n",
    "dim_r = 1\n",
    "dim_θ = 4 \n",
    "dim_w = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symolic_log_transition_density_generators = {\n",
    "    'local_gaussian (p = 2)': simsde.densities.local_gaussian_log_transition_density_ii,\n",
    "}\n",
    "jax_log_transition_densities = {\n",
    "    key: symnum.numpify(dim_x, dim_x, dim_θ, None, numpy_module=jnp)(\n",
    "        symbolic_transition_density_generator(\n",
    "            drift_position, drift_momentum, drift_rough, diff_coeff_rough\n",
    "        )\n",
    "    )\n",
    "    for key, symbolic_transition_density_generator in \n",
    "    symolic_log_transition_density_generators.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_likelihood_functions(log_transition_density):\n",
    "    \n",
    "    @jit\n",
    "    def log_likelihood_θ(θ, x_seq, t_seq):\n",
    "        log_transition_density_terms = vmap(log_transition_density, (0, 0, None, 0))(\n",
    "            x_seq[1:], x_seq[:-1], θ, t_seq[1:] - t_seq[:-1]\n",
    "        )\n",
    "        return log_transition_density_terms.sum()\n",
    "            \n",
    "    return {'θ': log_likelihood_θ}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_n, step_func = {\n",
    "    \"euler_maruyama\": (\n",
    "        dim_r,\n",
    "        simsde.integrators.euler_maruyama_step(drift_func, diff_coeff),\n",
    "    ),\n",
    "    \"local_gaussian_ii\": (\n",
    "        3*dim_r,\n",
    "        simsde.integrators.hypoelliptic_ii_local_gaussian_step(\n",
    "        drift_func, drift_rough, drift_position, drift_momentum, diff_coeff_rough)\n",
    "    )\n",
    "}[\"local_gaussian_ii\"]\n",
    "\n",
    "jax_step_func = symnum.numpify(dim_x, dim_θ, dim_n, (), numpy_module=jnp)(step_func)\n",
    "\n",
    "@jit\n",
    "def simulate_diffusion(x_0, θ, t_seq, n_seq):\n",
    "    \n",
    "    def step_func(x, n_dt):\n",
    "        n, dt = n_dt\n",
    "        x_next = jax_step_func(x, θ, n, dt)\n",
    "        return x_next, x_next\n",
    "    \n",
    "    _, x_seq = scan(step_func, x_0, (n_seq, t_seq[1:] - t_seq[:-1]))\n",
    "    \n",
    "    return jnp.concatenate((x_0[None], x_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting \n",
    "rng = np.random.default_rng(20230204)\n",
    "dt_simulation = 1e-4 # step size for synthetic data \n",
    "dt_obs = 1e-3  # step size for the observation \n",
    "T = 200 # Time length of data step\n",
    "n_simulation = int(T / dt_simulation)\n",
    "sub_interval = int(dt_obs/dt_simulation)\n",
    "n_data = int(T / dt_obs) # number of data \n",
    "θ_true = jnp.array([1.0, 2.0, 4.0, 1.0]) # param θ = (D, λ, α, σ) \n",
    "x_0 = jnp.array([0.0, 0.0, 0.0]) # initial value  \n",
    "t_seq_sim = np.arange(int(T / dt_simulation) + 1) * dt_simulation\n",
    "model = hypo_gle_ho(θ_true, x_0, dt_obs, dt_simulation, n_data, n_simulation)\n",
    "initial_mean = jnp.array([0.0, 0.0])\n",
    "initial_cov = jnp.array([[1.0, 0.0], [0.0, 1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_contrast_estimator(q_obs, θ_0, initial_mean, initial_cov, optimizer=adam, n_steps=5000, step_size= 1e-1):\n",
    "    optimizer_init, optimizer_update, optimizer_get_params = optimizer(step_size) \n",
    "\n",
    "    @jit\n",
    "    def optimizer_step(state, q_obs, initial_mean, initial_cov, step_index):\n",
    "        value, grad = value_and_grad(model.get_contrast_function_scan)(\n",
    "            optimizer_get_params(state), q_obs, initial_mean, initial_cov\n",
    "        )\n",
    "        state = optimizer_update(step_index, grad, state)\n",
    "        return value, state\n",
    "    \n",
    "    state = optimizer_init(θ_0)\n",
    "\n",
    "    for s in range(n_steps):\n",
    "        _, state = optimizer_step(state, q_obs, initial_mean, initial_cov, s)\n",
    "        print(optimizer_get_params(state))\n",
    "        \n",
    "    return optimizer_get_params(state)\n",
    "\n",
    "\n",
    "log_transition_density = jax_log_transition_densities[\"local_gaussian (p = 2)\"]\n",
    "log_likelihood = get_log_likelihood_functions(log_transition_density)\n",
    "\n",
    "def compute_complete_maximum_likelihood_estimates(\n",
    "    t_seq, x_seqs, θ_0, optimizer=adam, n_steps=5000, step_size=1e-1\n",
    "):\n",
    "    optimizer_init, optimizer_update, optimizer_get_params = optimizer(step_size)\n",
    "    \n",
    "    @jit \n",
    "    def optimizer_step(step_index, state, x_seq, t_seq):\n",
    "        value, grad = value_and_grad(log_likelihood[\"θ\"])(\n",
    "            optimizer_get_params(state), x_seq, t_seq\n",
    "        )\n",
    "        state = optimizer_update(step_index, -grad, state)\n",
    "        return value, state\n",
    "\n",
    "    state = optimizer_init(θ_0)\n",
    "\n",
    "    for s in range(n_steps):\n",
    "        _, state = optimizer_step(s, state, x_seqs, t_seq)\n",
    "        print(optimizer_get_params(state))\n",
    "        \n",
    "    return optimizer_get_params(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sampling = 30\n",
    "D_sample_complete = np.empty((num_sampling))\n",
    "λ_sample_complete = np.empty((num_sampling))\n",
    "α_sample_complete = np.empty((num_sampling))\n",
    "σ_sample_complete = np.empty((num_sampling))\n",
    "D_sample_partial = np.empty((num_sampling))\n",
    "λ_sample_partial = np.empty((num_sampling))\n",
    "α_sample_partial = np.empty((num_sampling))\n",
    "σ_sample_partial = np.empty((num_sampling))\n",
    "seed = 20230624\n",
    "\n",
    "for k in range(num_sampling):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n_seqs = rng.standard_normal((t_seq_sim.shape[0] - 1, dim_n))\n",
    "    print(\"Compute the observations -- Start\")\n",
    "    x_seqs_sim = simulate_diffusion(x_0, θ_true, t_seq_sim, n_seqs)\n",
    "    x_seq_obs = x_seqs_sim[::sub_interval]\n",
    "    print(\"Compute the observations -- End\")\n",
    "    q_paths_obs = x_seq_obs[:, 2]\n",
    "    t_seq_obs = t_seq_sim[::sub_interval]\n",
    "    θ_0 = jnp.array([2.0, 2.0, 2.0, 2.0])\n",
    "    print(\"Optimisation Complete Observation Adam -- Start\")\n",
    "    complete_adam = compute_complete_maximum_likelihood_estimates(t_seq_obs, x_seq_obs, θ_0)\n",
    "    print(\"Optimisation Complete Observation Adam -- End\")\n",
    "    print(complete_adam)\n",
    "    print(value_and_grad(log_likelihood[\"θ\"])(complete_adam, x_seq_obs, t_seq_obs))\n",
    "    print(\"Optimisation Partial Observation Adam -- Start\")\n",
    "    θ_0 = jnp.array([2.0, 2.0, 2.0, 2.0])\n",
    "    partial_adam = compute_contrast_estimator(q_paths_obs, θ_0, initial_mean, initial_cov)\n",
    "    print(\"Optimisation Partial Observation Adam -- End\")\n",
    "    print(partial_adam)\n",
    "    print(value_and_grad(model.get_contrast_function_scan)(partial_adam, q_paths_obs, initial_mean, initial_cov))\n",
    "    print(k)\n",
    "    D_sample_complete[k] = complete_adam[0]\n",
    "    λ_sample_complete[k] = complete_adam[1]\n",
    "    α_sample_complete[k] = complete_adam[2]\n",
    "    σ_sample_complete[k] = complete_adam[3]\n",
    "    D_sample_partial[k] = partial_adam[0]\n",
    "    λ_sample_partial[k] = partial_adam[1]\n",
    "    α_sample_partial[k] = partial_adam[2]\n",
    "    σ_sample_partial[k] = partial_adam[3]\n",
    "    seed += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(f'MLE_GLE_HO_complete={T}_dt_obs_{dt_obs}_dt_sim_{dt_simulation}.csv', 'w')\n",
    "writer = csv.writer(f, delimiter='\\t')\n",
    "writer.writerow(D_sample_complete)\n",
    "writer.writerow(λ_sample_complete)\n",
    "writer.writerow(α_sample_complete)\n",
    "writer.writerow(σ_sample_complete)\n",
    "f.close()\n",
    "\n",
    "f = open(f'MLE_GLE_HO_partial={T}_dt_obs_{dt_obs}_dt_sim_{dt_simulation}.csv', 'w')\n",
    "writer = csv.writer(f, delimiter='\\t')\n",
    "writer.writerow(D_sample_partial)\n",
    "writer.writerow(λ_sample_partial)\n",
    "writer.writerow(α_sample_partial)\n",
    "writer.writerow(σ_sample_partial)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
